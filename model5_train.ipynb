{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 78272,
          "databundleVersionId": 8577682,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "notebookf8883d7abd"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-classification-2024-spring:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F78272%2F8577682%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240614%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240614T073446Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dae29bf1b8438cdfccbbd16b53f5105f025a9f1a9104a7d119e56633501b9ce2fceb0233adbda03940a7be45d74b7b6f2b05d702484bd09481960b3a7f0c8bf01e3df0a4276641748c9d5abd6b546f09523acedc17f93c4c4c136f83346a610a7a0a7041368b0d0251cf0cc27f76fda6182017f5fa6970fda1c6916c8a90901e9b204934a33e967bd7c0257c42135dc500fbfde200cf5001c5ce7b1bfb5080e92e7ba33d02c3f464185e896b21fb9cdc091315b41c94576e741bc8aaacb85cca105fc123a368fbc60020b2c11e245889edc6aebd37d4687b0deb45826e3e3ea21bed51bdf8098749b825a830b40d3b280a44b35cfccd1f03e37012f8c79849ded'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pq6Fbljq6IG",
        "outputId": "6948efe4-28c5-412d-f1ac-adcf44b08b2e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading image-classification-2024-spring, 1250295019 bytes compressed\n",
            "[==================================================] 1250295019 bytes downloaded\n",
            "Downloaded and uncompressed: image-classification-2024-spring\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "-ftMT3_7ctCV",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:52.008399Z",
          "iopub.execute_input": "2024-06-14T05:36:52.008659Z",
          "iopub.status.idle": "2024-06-14T05:36:58.077489Z",
          "shell.execute_reply.started": "2024-06-14T05:36:52.008635Z",
          "shell.execute_reply": "2024-06-14T05:36:58.07655Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(7)"
      ],
      "metadata": {
        "id": "S9hKDvXictCW",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.079323Z",
          "iopub.execute_input": "2024-06-14T05:36:58.079755Z",
          "iopub.status.idle": "2024-06-14T05:36:58.114047Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.079712Z",
          "shell.execute_reply": "2024-06-14T05:36:58.11314Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIfzS2CYctCW",
        "outputId": "c50dbc96-419b-4047-99f0-e492f7e67865",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.115288Z",
          "iopub.execute_input": "2024-06-14T05:36:58.115603Z",
          "iopub.status.idle": "2024-06-14T05:36:58.126724Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.115578Z",
          "shell.execute_reply": "2024-06-14T05:36:58.125789Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n"
      ],
      "metadata": {
        "id": "OMD50RLpctCW",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.128841Z",
          "iopub.execute_input": "2024-06-14T05:36:58.129121Z",
          "iopub.status.idle": "2024-06-14T05:36:58.13644Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.129097Z",
          "shell.execute_reply": "2024-06-14T05:36:58.13557Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JpegCompression(transforms.Lambda):\n",
        "    def __init__(self, quality_lower=60, quality_upper=100, p=0.5):\n",
        "        super().__init__(self.apply_jpeg_compression)\n",
        "        self.quality_lower = quality_lower\n",
        "        self.quality_upper = quality_upper\n",
        "        self.probability = p\n",
        "\n",
        "    def apply_jpeg_compression(self, img):\n",
        "        if random.random() < self.probability:\n",
        "            quality = random.randint(self.quality_lower, self.quality_upper)\n",
        "            buffer = io.BytesIO()\n",
        "            img.save(buffer, format=\"JPEG\", quality=quality)\n",
        "            buffer.seek(0)\n",
        "            img = Image.open(buffer)\n",
        "        return img"
      ],
      "metadata": {
        "id": "REH7Et_UctCW",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.137404Z",
          "iopub.execute_input": "2024-06-14T05:36:58.137675Z",
          "iopub.status.idle": "2024-06-14T05:36:58.14776Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.137651Z",
          "shell.execute_reply": "2024-06-14T05:36:58.146932Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_color_jitter():\n",
        "    return transforms.ColorJitter(\n",
        "        brightness=random.uniform(0.1, 0.3),\n",
        "        contrast=random.uniform(0.1, 0.3),\n",
        "        saturation=random.uniform(0.1, 0.3)\n",
        "    )"
      ],
      "metadata": {
        "id": "rlbGBbINctCW",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.148973Z",
          "iopub.execute_input": "2024-06-14T05:36:58.149933Z",
          "iopub.status.idle": "2024-06-14T05:36:58.159058Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.149907Z",
          "shell.execute_reply": "2024-06-14T05:36:58.15819Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalResize:\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if max(img.size) < self.target_size:\n",
        "            return transforms.Resize(self.target_size, interpolation=transforms.InterpolationMode.BILINEAR)(img)\n",
        "        return img"
      ],
      "metadata": {
        "id": "6C_3VCpqeLMv",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.160205Z",
          "iopub.execute_input": "2024-06-14T05:36:58.160463Z",
          "iopub.status.idle": "2024-06-14T05:36:58.16954Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.160441Z",
          "shell.execute_reply": "2024-06-14T05:36:58.168785Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import io\n",
        "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
        "\n",
        "# 필요한 크기\n",
        "target_size = 380\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    ConditionalResize(target_size),  # target_size보다 작은 경우에만 리사이즈\n",
        "    transforms.CenterCrop(target_size),  # 모든 이미지를 target_size로 중앙 자르기\n",
        "    JpegCompression(quality_lower=60, quality_upper=90, p=0.2),\n",
        "    transforms.RandomApply([  # 색상 조정을 랜덤하게 적용\n",
        "        transforms.Lambda(lambda img: random_color_jitter()(img))\n",
        "    ], p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "xdIos9yKctCX",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.184041Z",
          "iopub.execute_input": "2024-06-14T05:36:58.184282Z",
          "iopub.status.idle": "2024-06-14T05:36:58.195017Z",
          "shell.execute_reply.started": "2024-06-14T05:36:58.184262Z",
          "shell.execute_reply": "2024-06-14T05:36:58.19415Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root='/kaggle/input/image-classification-2024-spring/dataset/train', transform=transform)"
      ],
      "metadata": {
        "id": "7U5sDJqHctCX",
        "execution": {
          "iopub.status.busy": "2024-06-14T05:36:58.198729Z",
          "iopub.execute_input": "2024-06-14T05:36:58.19905Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(dataset)\n",
        "train_size = int(dataset_size * 0.95)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "trainset, valset = random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "y_NzbMSXctCX",
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnN5fJHIctCX",
        "outputId": "9aa9c72e-c82d-4105-e6d8-49fb21d59a98",
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "# EfficientNet V2-S 모델을 불러옵니다. 미리 학습된 가중치를 사용합니다.\n",
        "model = models.efficientnet_v2_s(pretrained=True)\n",
        "\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# model = nn.DataParallel(model, device_ids=[0, 1])\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsUnqbmsctCX",
        "outputId": "e6ffc7bb-a25e-4886-8e14-d86a5cdbac51",
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=40, gamma=0.5)"
      ],
      "metadata": {
        "id": "CN7Kmy0actCY",
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('checkpoint'):\n",
        "    os.makedirs('checkpoint')\n",
        "\n",
        "best_acc = 0."
      ],
      "metadata": {
        "id": "cAmCgCK4ctCY",
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    for inputs, label in tqdm(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, label.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        preds += predicted.detach().cpu().numpy().tolist()\n",
        "        labels += label.detach().cpu().numpy().tolist()\n",
        "\n",
        "    train_accuracy = accuracy_score(labels, preds)\n",
        "    print(f'train_accuracy: {train_accuracy}')\n",
        "\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, label in tqdm(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            preds += predicted.detach().cpu().numpy().tolist()\n",
        "            labels += label.detach().cpu().numpy().tolist()\n",
        "\n",
        "    val_accuracy = accuracy_score(labels, preds)\n",
        "    print(f'val_accuracy: {val_accuracy}')\n",
        "\n",
        "    if epoch == 14:\n",
        "        best_acc = val_accuracy\n",
        "        torch.save(model.state_dict(), 'checkpoint/model5.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "oDrMmWWuctCY",
        "outputId": "94462d4b-67dc-4d96-a05b-f84556eee2fc",
        "execution": {
          "iopub.status.idle": "2024-06-14T07:07:57.318494Z",
          "shell.execute_reply.started": "2024-06-14T05:42:44.67237Z",
          "shell.execute_reply": "2024-06-14T07:07:57.317509Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 482/594 [07:45<01:48,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-35e6e21a863f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}