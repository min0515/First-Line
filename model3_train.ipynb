{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78272,"databundleVersionId":8577682,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\n\nfrom torchvision import datasets, transforms\n\nfrom sklearn.metrics import accuracy_score\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport random\nfrom tqdm import tqdm\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-13T20:17:35.092554Z","iopub.execute_input":"2024-06-13T20:17:35.093059Z","iopub.status.idle":"2024-06-13T20:17:42.431103Z","shell.execute_reply.started":"2024-06-13T20:17:35.093025Z","shell.execute_reply":"2024-06-13T20:17:42.430117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(7)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.433417Z","iopub.execute_input":"2024-06-13T20:17:42.434677Z","iopub.status.idle":"2024-06-13T20:17:42.469054Z","shell.execute_reply.started":"2024-06-13T20:17:42.434635Z","shell.execute_reply":"2024-06-13T20:17:42.467897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.474673Z","iopub.execute_input":"2024-06-13T20:17:42.475053Z","iopub.status.idle":"2024-06-13T20:17:42.483280Z","shell.execute_reply.started":"2024-06-13T20:17:42.475023Z","shell.execute_reply":"2024-06-13T20:17:42.482056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JpegCompression(transforms.Lambda):\n    def __init__(self, quality_lower=60, quality_upper=100, p=0.5):\n        super().__init__(self.apply_jpeg_compression)\n        self.quality_lower = quality_lower\n        self.quality_upper = quality_upper\n        self.probability = p\n\n    def apply_jpeg_compression(self, img):\n        if random.random() < self.probability:\n            quality = random.randint(self.quality_lower, self.quality_upper)\n            buffer = io.BytesIO()\n            img.save(buffer, format=\"JPEG\", quality=quality)\n            buffer.seek(0)\n            img = Image.open(buffer)\n        return img","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.484662Z","iopub.execute_input":"2024-06-13T20:17:42.485359Z","iopub.status.idle":"2024-06-13T20:17:42.493706Z","shell.execute_reply.started":"2024-06-13T20:17:42.485330Z","shell.execute_reply":"2024-06-13T20:17:42.492732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_color_jitter():\n    return transforms.ColorJitter(\n        brightness=random.uniform(0.1, 0.3),\n        contrast=random.uniform(0.1, 0.3),\n        saturation=random.uniform(0.1, 0.3)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.494965Z","iopub.execute_input":"2024-06-13T20:17:42.495253Z","iopub.status.idle":"2024-06-13T20:17:42.505870Z","shell.execute_reply.started":"2024-06-13T20:17:42.495228Z","shell.execute_reply":"2024-06-13T20:17:42.504767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Crop20(object):\n    def __call__(self, image):\n        if image.size == (1080, 1920):\n            return image.crop((0,0,1080,1536))\n        else:\n            return image\n        \nclass ConditionalResize:\n    def __init__(self, target_size):\n        self.target_size = target_size\n\n    def __call__(self, img):\n        if max(img.size) < self.target_size:\n            return transforms.Resize(self.target_size, interpolation=transforms.InterpolationMode.BILINEAR)(img)\n        return img","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.507180Z","iopub.execute_input":"2024-06-13T20:17:42.507488Z","iopub.status.idle":"2024-06-13T20:17:42.516925Z","shell.execute_reply.started":"2024-06-13T20:17:42.507463Z","shell.execute_reply":"2024-06-13T20:17:42.515874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport io\n\ntarget_size = 380\ntransform = transforms.Compose([\n    Crop20(),\n    ConditionalResize(target_size),\n    transforms.CenterCrop(target_size),\n    JpegCompression(quality_lower=60, quality_upper=90, p=0.2),\n    transforms.RandomApply([ \n        transforms.Lambda(lambda img: random_color_jitter()(img))\n    ], p=0.2),\n    transforms.RandomPerspective(0.1, 0.1),\n    transforms.RandomHorizontalFlip(0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.518254Z","iopub.execute_input":"2024-06-13T20:17:42.519741Z","iopub.status.idle":"2024-06-13T20:17:42.531576Z","shell.execute_reply.started":"2024-06-13T20:17:42.519712Z","shell.execute_reply":"2024-06-13T20:17:42.530347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.ImageFolder(root='/kaggle/input/image-classification-2024-spring/dataset/train', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:42.532814Z","iopub.execute_input":"2024-06-13T20:17:42.533226Z","iopub.status.idle":"2024-06-13T20:17:56.781719Z","shell.execute_reply.started":"2024-06-13T20:17:42.533186Z","shell.execute_reply":"2024-06-13T20:17:56.780427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_size = len(dataset)\ntrain_size = int(dataset_size * 0.95)\nval_size = dataset_size - train_size\n\ntrainset, valset = random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:56.785014Z","iopub.execute_input":"2024-06-13T20:17:56.785350Z","iopub.status.idle":"2024-06-13T20:17:56.813971Z","shell.execute_reply.started":"2024-06-13T20:17:56.785322Z","shell.execute_reply":"2024-06-13T20:17:56.812989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\nval_loader = DataLoader(valset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:56.815048Z","iopub.execute_input":"2024-06-13T20:17:56.815351Z","iopub.status.idle":"2024-06-13T20:17:56.821340Z","shell.execute_reply.started":"2024-06-13T20:17:56.815326Z","shell.execute_reply":"2024-06-13T20:17:56.820350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nmodel = models.efficientnet_v2_s(pretrained=True)\n\nnum_ftrs = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_ftrs, 2)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:56.822716Z","iopub.execute_input":"2024-06-13T20:17:56.823057Z","iopub.status.idle":"2024-06-13T20:17:58.778244Z","shell.execute_reply.started":"2024-06-13T20:17:56.823031Z","shell.execute_reply":"2024-06-13T20:17:58.777188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(train_loader)\ncriterion = nn.CrossEntropyLoss()\noptimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\nscheduler = OneCycleLR(\n    optimizer,\n    max_lr=1e-3,             \n    epochs=7,             \n    steps_per_epoch=steps_per_epoch\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:58.779627Z","iopub.execute_input":"2024-06-13T20:17:58.780087Z","iopub.status.idle":"2024-06-13T20:17:58.790467Z","shell.execute_reply.started":"2024-06-13T20:17:58.780048Z","shell.execute_reply":"2024-06-13T20:17:58.789290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('checkpoint'):\n    os.makedirs('checkpoint')\n\nbest_acc = 0.","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:58.791744Z","iopub.execute_input":"2024-06-13T20:17:58.792114Z","iopub.status.idle":"2024-06-13T20:17:58.806136Z","shell.execute_reply.started":"2024-06-13T20:17:58.792087Z","shell.execute_reply":"2024-06-13T20:17:58.804975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(7):\n    model.train()\n    running_loss = 0.0\n    preds = []\n    labels = []\n\n    for inputs, label in tqdm(train_loader):\n        inputs = inputs.to(device)\n        label = label.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, label.long())\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        preds += predicted.detach().cpu().numpy().tolist()\n        labels += label.detach().cpu().numpy().tolist()\n\n    train_accuracy = accuracy_score(labels, preds)\n    print(f'train_accuracy: {train_accuracy}')\n\n    model.eval()\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        for inputs, label in tqdm(val_loader):\n            inputs = inputs.to(device)\n            label = label.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            val_preds += predicted.detach().cpu().numpy().tolist()\n            val_labels += label.detach().cpu().numpy().tolist()\n\n    val_accuracy = accuracy_score(val_labels, val_preds)\n    print(f'val_accuracy: {val_accuracy}')\n\n    if epoch == 6:\n        torch.save(model.state_dict(), f'checkpoint/model3.pth')\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:17:58.807430Z","iopub.execute_input":"2024-06-13T20:17:58.807760Z","iopub.status.idle":"2024-06-13T20:48:31.365963Z","shell.execute_reply.started":"2024-06-13T20:17:58.807732Z","shell.execute_reply":"2024-06-13T20:48:31.364932Z"},"trusted":true},"execution_count":null,"outputs":[]}]}